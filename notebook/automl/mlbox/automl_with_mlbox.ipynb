{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "I’ll show you how you can easily use it to train an automated machine learning pipeline for a classification problem. \n",
    "__It’ll start by loading and cleaning the data, removing drift, launching a strong pipeline of accelerated optimization and generating predictions.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLBox: a fully automated pipeline\n",
    "![title](assets/MlBox.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Initialisation:__\n",
    "> __From a raw dataset to a cleaned dataset with numerical features.__\n",
    "\n",
    "- Files reading:\n",
    "> Reading of several files (csv, xls, json and hdf5)\\\n",
    "> Task detection (binary/multiclass classification or regression)\\\n",
    "> Creation of the training data set and the test data set\n",
    "- Preprocessing/cleaning:\n",
    "> Dropping duplicates and constant features\\\n",
    "> Dropping drifting features\n",
    "- Encoding:\n",
    "> Converting features to a unique format (float if possible or str)\\\n",
    "> Converting lists\\\n",
    "> Converting dates into timestamp\\\n",
    "> Target encoding for classification task only\\\n",
    "> Categorical features encoding (several strategies available !)\\\n",
    "> Missing values encoding (several strategies available !)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation:\n",
    "> __Several models are tested and cross-validated and the best one is fitted.__\n",
    "\n",
    "- On features:\n",
    "> Feature engineering : neural network features engineering\\\n",
    "> Feature selection : filter methods, wrapper methods and L1 regularization\n",
    "- On estimator:\n",
    "> TestIng of a wide range of accurate estimators: Linear model, Random Forest, XGBoost, LightGBM… \\\n",
    "> Model blending: stacking, boosting, bagging\n",
    "> Hyper-parameters tuning (using TPE algorithm)\n",
    "- On validation :\n",
    "> Choice of several metrics: accuracy, log-loss, AUC, f1-score, MSE, MAE, ETC ..\\\n",
    "> Validation parameters: number of folds, random state, …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Application:\n",
    "> __We fit the whole pipeline and predict the target on the test set.__\n",
    "\n",
    "- Prediction:\n",
    "> Target prediction (class probabilities for classification)\\\n",
    "> Dumping fitted models and final predictions (.csv file)\\\n",
    "> CPU time display\n",
    "- Models interpretation:\n",
    ">Features importance\\\n",
    "> Leak detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MLBox: from data ingestion to model building\n",
    "\n",
    "Now we’re going to test and run MLBox to quickly build a model to solve the Kaggle Titanic Challenge.\n",
    "\n",
    "## Importing MLBox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 166 ms, total: 1.63 s\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from mlbox.preprocessing.reader import Reader\n",
    "from mlbox.preprocessing.drift_thresholder import Drift_thresholder\n",
    "from mlbox.optimisation.optimiser import Optimiser \n",
    "from mlbox.prediction.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"/data1/kaggle/titanic/train.csv\", \"/data1/kaggle/titanic/test.csv\"] \n",
    "target_name = \"Survived\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and preprocessing\n",
    "\n",
    "The Reader class of MLBox is in charge of preparing the data.\n",
    "It provides methods and utilities to:\n",
    "1. Read in the data with the correct separator (CSV, XLS, JSON, and h5) and load it\n",
    "2. Clean the data by:\n",
    " - deleting Unnamed column\n",
    " - inferring column types (float, int, list)\n",
    " - processing dates and extracting relevant information from it: year, month, day, day_of_week, hour, etc.\n",
    " - removing duplicates\n",
    " - preparing train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : train.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 4.343689680099487 seconds\n",
      "\n",
      "reading csv : test.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.05657672882080078 seconds\n",
      "\n",
      "> Number of common features : 11\n",
      "\n",
      "gathering and crunching for train and test datasets ...\n",
      "reindexing for train and test datasets ...\n",
      "dropping training duplicates ...\n",
      "dropping constant variables on training set ...\n",
      "\n",
      "> Number of categorical features: 5\n",
      "> Number of numerical features: 6\n",
      "> Number of training samples : 891\n",
      "> Number of test samples : 418\n",
      "\n",
      "> Top sparse features (% missing values on train set):\n",
      "Cabin       77.1\n",
      "Age         19.9\n",
      "Embarked     0.2\n",
      "dtype: float64\n",
      "\n",
      "> Task : classification\n",
      "0.0    549\n",
      "1.0    342\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "encoding target ...\n"
     ]
    }
   ],
   "source": [
    "rd = Reader(sep=\",\")\n",
    "df = rd.train_test_split(paths, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris    0.0          1.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0.0          2.0   \n",
       "2                             Heikkinen, Miss. Laina    0.0          3.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0.0          4.0   \n",
       "4                           Allen, Mr. William Henry    0.0          5.0   \n",
       "\n",
       "   Pclass     Sex  SibSp            Ticket  \n",
       "0     3.0    male    1.0         A/5 21171  \n",
       "1     1.0  female    1.0          PC 17599  \n",
       "2     3.0  female    0.0  STON/O2. 3101282  \n",
       "3     1.0  female    1.0            113803  \n",
       "4     3.0    male    0.0            373450  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing drift\n",
    "![title](assets/Drift.PNG)\n",
    "This is an innovative feature I haven’t encountered in other packages. __The main idea is to automatically detect and remove variables that have a distribution that is substantially different between the train and the test set.__\n",
    "This happens quite a lot and we generally talk about biased data. __You could have for example a situation when the train set has a population of young people whereas the test has elderly only.__ This indicates that the age feature is not robust and may lead to poor performance of the model when testing. So it has to be discarded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does MLBox compute drifts for individual variables\n",
    "MLBox builds a classifier that separates train from test data. __It then uses the ROC score related to this classifier as a measure of the drift.__\n",
    "This makes sense:\n",
    "- If the drift score is high (i.e. the ROC score is high) the ability the discern train data from test data is easy, which means that the two distributions are very different.\n",
    "- Otherwise, if the drift score is low (i.e. the ROC score is low) the classifier is not able to separate the two distributions correctly.\n",
    "\n",
    "MLBox provides a class called Drift_thresholder that takes as input the train and test sets as well as the target and computes a drift score of each one of the variables.\n",
    "__Drift_thresholder then deletes the variables that have a drift score higher than a threshold (default to 0.6).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing drifts ...\n",
      "CPU time: 2.5861728191375732 seconds\n",
      "\n",
      "> Top 10 drifts\n",
      "\n",
      "('PassengerId', 0.9976076555023923)\n",
      "('Name', 0.992967794537301)\n",
      "('Ticket', 0.6848477696483359)\n",
      "('Cabin', 0.18840282467093372)\n",
      "('Embarked', 0.07221893417659442)\n",
      "('Fare', 0.05512063216621499)\n",
      "('Sex', 0.046565327627161146)\n",
      "('Pclass', 0.02446271392419952)\n",
      "('Age', 0.014791769476688144)\n",
      "('SibSp', 0.00920393884026205)\n",
      "\n",
      "> Deleted variables : ['Name', 'PassengerId', 'Ticket']\n",
      "> Drift coefficients dumped into directory : save\n"
     ]
    }
   ],
   "source": [
    "dft = Drift_thresholder()\n",
    "df = dft.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  Parch  Pclass     Sex  SibSp\n",
       "0  22.0   NaN        S   7.2500    0.0     3.0    male    1.0\n",
       "1  38.0   C85        C  71.2833    0.0     1.0  female    1.0\n",
       "2  26.0   NaN        S   7.9250    0.0     3.0  female    0.0\n",
       "3  35.0  C123        S  53.1000    0.0     1.0  female    1.0\n",
       "4  35.0   NaN        S   8.0500    0.0     3.0    male    0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The heavy lifting: optimizing\n",
    "This section performs the optimization of the pipeline and tries different configurations of the parameters:\n",
    "- NA encoder (missing values encoder)\n",
    "- CA encoder (categorical features encoder)\n",
    "- Feature selector (OPTIONAL)\n",
    "- Stacking estimator — feature engineer (OPTIONAL)\n",
    "- Estimator (classifier or regressor)\n",
    "\n",
    "Run it using the default model configuration set as default (LightGBM) without any autoML or complex grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parameters set. Default configuration is tested\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "\n",
      "\n",
      "MEAN SCORE : neg_log_loss = -0.6324717748298669\n",
      "VARIANCE : 0.003224557409561235 (fold 1 = -0.6356963322394281, fold 2 = -0.6292472174203056)\n",
      "CPU time: 0.5325939655303955 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "opt = Optimiser()\n",
    "score = opt.evaluate(None, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neg log loss = -0.6325 as a first baseline.\n",
    "\n",
    "Let’s now define a space of multiple configurations:\n",
    "- ne__numerical_strategy: how to handle missing data in numerical features\n",
    "- ce__strategy: how to handle categorical variables encoding\n",
    "- fs: feature selection\n",
    "- stck: meta-features stacker\n",
    "- est: final estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}   \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.08234297303219519}\n",
      ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 11, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.4744557540842814     \n",
      "VARIANCE : 0.026845474941050024 (fold 1 = -0.5013012290253315, fold 2 = -0.4476102791432314)\n",
      "CPU time: 2.2562050819396973 seconds                \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                            \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.020715406219129595}  \n",
      ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 9, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.44071037386542555                             \n",
      "VARIANCE : 0.017300395912091482 (fold 1 = -0.45801076977751704, fold 2 = -0.42340997795333407)\n",
      "CPU time: 1.0675585269927979 seconds                                         \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                              \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.07182441781415833}    \n",
      ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 8, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      " 13%|█▎        | 2/15 [00:03<00:24,  1.92s/it, best loss: 0.44071037386542555]WARNING:tensorflow:From /home/labs/anaconda3/envs/automl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/labs/anaconda3/envs/automl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/labs/anaconda3/envs/automl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/labs/anaconda3/envs/automl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/labs/anaconda3/envs/automl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/labs/anaconda3/envs/automl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/labs/anaconda3/envs/automl/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/labs/anaconda3/envs/automl/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "MEAN SCORE : neg_log_loss = -0.5865340530830648                               \n",
      "VARIANCE : 0.11389343182852829 (fold 1 = -0.7004274849115931, fold 2 = -0.47264062125453654)\n",
      "CPU time: 3.5624783039093018 seconds                                          \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                              \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.18507088580226294}    \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 10, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : neg_log_loss = -0.9648304127938878                               \n",
      "VARIANCE : 0.20114182825449883 (fold 1 = -1.1659722410483866, fold 2 = -0.7636885845393889)\n",
      "CPU time: 0.5725829601287842 seconds                                          \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                              \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.11182673370622212}    \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 10, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : neg_log_loss = -0.9741347582202667                               \n",
      "VARIANCE : 0.22588580040468165 (fold 1 = -1.2000205586249484, fold 2 = -0.7482489578155851)\n",
      "CPU time: 3.093573570251465 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.1370337745364344}     \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 9, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : neg_log_loss = -0.6356866326954257                               \n",
      "VARIANCE : 0.02212777319535897 (fold 1 = -0.6578144058907847, fold 2 = -0.6135588595000667)\n",
      "CPU time: 0.45307374000549316 seconds                                         \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                             \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.18458019695555747}    \n",
      ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 10, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.4450420921902324                               \n",
      "VARIANCE : 0.022249229840739182 (fold 1 = -0.46729132203097157, fold 2 = -0.4227928623494932)\n",
      "CPU time: 1.048898696899414 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                              \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.06705591768129572}    \n",
      ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 9, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.5435393418162481                               \n",
      "VARIANCE : 0.04316070986504139 (fold 1 = -0.5867000516812895, fold 2 = -0.5003786319512067)\n",
      "CPU time: 1.121394395828247 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                             \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.07867387883769673}    \n",
      ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 13, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.4828276129642152                               \n",
      "VARIANCE : 0.02348264220085544 (fold 1 = -0.5063102551650707, fold 2 = -0.4593449707633598)\n",
      "CPU time: 1.0688681602478027 seconds                                          \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                             \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.06400846545317443}    \n",
      ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 9, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.4419602311791781                               \n",
      "VARIANCE : 0.01745469028459462 (fold 1 = -0.4594149214637727, fold 2 = -0.4245055408945835)\n",
      "CPU time: 1.061692476272583 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                              \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.163229062089846}       \n",
      ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 9, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.44071037386542555                               \n",
      "VARIANCE : 0.017300395912091482 (fold 1 = -0.45801076977751704, fold 2 = -0.42340997795333407)\n",
      "CPU time: 1.0683820247650146 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}    \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                              \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.1451475182026108}      \n",
      ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 11, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.4501929776672017                                \n",
      "VARIANCE : 0.022680430146820724 (fold 1 = -0.4728734078140224, fold 2 = -0.4275125475203809)\n",
      "CPU time: 1.0294649600982666 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                               \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.18854931057942984}     \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 13, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : neg_log_loss = -0.9589796922107463                                \n",
      "VARIANCE : 0.1974662957621729 (fold 1 = -1.1564459879729192, fold 2 = -0.7615133964485734)\n",
      "CPU time: 0.5684912204742432 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}    \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                 \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.0890926465346568}      \n",
      ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 9, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : neg_log_loss = -0.4498366358215057                                \n",
      "VARIANCE : 0.022433481491541535 (fold 1 = -0.4722701173130472, fold 2 = -0.4274031543299641)\n",
      "CPU time: 1.0189557075500488 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                 \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.07128763220975241}     \n",
      ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 9, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "MEAN SCORE : neg_log_loss = -0.43670643159910416                               \n",
      "VARIANCE : 0.015293572488890544 (fold 1 = -0.45200000408799473, fold 2 = -0.42141285911021364)\n",
      "CPU time: 1.0682754516601562 seconds                                           \n",
      "100%|██████████| 15/15 [00:20<00:00,  1.35s/it, best loss: 0.43670643159910416]\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "{'ce__strategy': 'label_encoding', 'est__max_depth': 9, 'est__strategy': 'ExtraTrees', 'fs__threshold': 0.07128763220975241, 'ne__numerical_strategy': 'mean'}\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.07128763220975241}\n",
      "\n",
      ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 9, 'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 400, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "\n",
      "MEAN SCORE : neg_log_loss = -0.43670643159910416\n",
      "VARIANCE : 0.015293572488890517 (fold 1 = -0.4520000040879947, fold 2 = -0.42141285911021364)\n",
      "CPU time: 1.024888515472412 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.43670643159910416"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = {\n",
    "        'ne__numerical_strategy':{\"search\":\"choice\",\n",
    "                                 \"space\":[0, \"mean\"]},\n",
    "        'ce__strategy':{\"search\":\"choice\",\n",
    "                        \"space\":[\"label_encoding\", \"random_projection\", \"entity_embedding\"]}, \n",
    "        'fs__threshold':{\"search\":\"uniform\",\n",
    "                        \"space\":[0.001, 0.2]}, \n",
    "        'est__strategy':{\"search\":\"choice\", \n",
    "                         \"space\":[\"RandomForest\", \"ExtraTrees\", \"LightGBM\"]},\n",
    "        'est__max_depth':{\"search\":\"choice\", \n",
    "                          \"space\":[8, 9, 10, 11, 12, 13]}\n",
    "        }\n",
    "\n",
    "params = opt.optimise(space, df, 15)\n",
    "opt.evaluate(params, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this pipeline resulted in a higher neg loss, which is better.\n",
    "There’s a very good potential of more improvement if we define a better space of search or stacking operations and maybe other feature selection techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running predictions\n",
    " Fit the optimal pipeline and predict our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fitting the pipeline ...\n",
      "CPU time: 1.4750120639801025 seconds\n",
      "\n",
      "> Feature importances dumped into directory : save\n",
      "\n",
      "predicting ...\n",
      "CPU time: 0.22813796997070312 seconds\n",
      "\n",
      "> Overview on predictions : \n",
      "\n",
      "        0.0       1.0  Survived_predicted\n",
      "0  0.897952  0.102048                   0\n",
      "1  0.656720  0.343280                   0\n",
      "2  0.854128  0.145872                   0\n",
      "3  0.881991  0.118009                   0\n",
      "4  0.531964  0.468036                   0\n",
      "5  0.840353  0.159647                   0\n",
      "6  0.346359  0.653641                   1\n",
      "7  0.775022  0.224978                   0\n",
      "8  0.295327  0.704673                   1\n",
      "9  0.890721  0.109279                   0\n",
      "\n",
      "dumping predictions into directory : save ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlbox.prediction.predictor.Predictor at 0x7f6410ac1588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd = Predictor()\n",
    "prd.fit_predict(params, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "With MLBox, you can do this very quickly and efficiently so that you can focus on what matters when solving a business problem.\n",
    " - Understanding the problem\n",
    " - Acquiring and consolidating the right data\n",
    " - Formalizing the performance metrics to reach and compute\n",
    " \n",
    "해결 해야 할 문제를 효율적이고 빠르게 프로토 타입화 할 수 있기에, 직관적으로 문제의 전체적인 흐름을 인지할 수 있게 하여, 근본적인 문제의 원인 분석에 좀 더 집중 할 수 있도록 도움을 준다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl",
   "language": "python",
   "name": "automl"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
