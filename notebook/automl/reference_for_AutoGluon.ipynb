{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is AutoGluon?\n",
    "\n",
    "AutoGluon is a new __open source AutoML library that automates deep learning (DL) and machine learning (ML)__ for real world applications involving image, text and tabular datasets. With AutoGluon, you can develop and refine state-of-the-art DL models using just a few lines of Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "- Historically, achieving state-of-the-art ML performance required extensive background knowledge, experience, and human effort. \n",
    "- Data preparation, feature engineering, validation splitting, missing value handling, and model selection are just a few of the many tasks that must be addressed in ML applications. One particularly difficult task is the selection of hyperparameters.\n",
    "- Hyperparameters represent the many choices that must be made by the user when constructing a model, such as the data processing steps, neural network architecture, and the optimizer used during training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Features\n",
    "\n",
    "- AutoGluon will leverage the available compute resources to find the strongest ML methods within its allotted run-time.\n",
    "- AutoGluon enables you to automatically __achieve state-of-the-art performance on tasks such as image classification, object detection, text classification, and supervised learning with tabular datasets.__ \n",
    "- __The hyperparameters of each task are automatically selected using advanced tuning algorithms such as Bayesian Optimization, Hyperband,__ \n",
    "- Reinforcement Learning. With AutoGluon, you don’t have to have any familiarity with the underlying models, as all hyperparameters will be automatically tuned within default ranges that are known to perform well for the particular task and model.\n",
    "- For expert ML practitioners, AutoGluon allows this process to be easily customized. For example, you can specify ranges of values to consider for certain hyperparameters, and also use AutoGluon to automatically tune various aspects of your own custom models. \n",
    "- If you have access to multiple machines, AutoGluon can easily distribute its computation across them in order to return trained models more quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "- CUDA 10.0 and a GPU for object detection is recommended\n",
    "- autogluon have dependency of mxnet\n",
    "\n",
    "pip install --upgrade mxnet-cu100\\\n",
    "pip install autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    ">__Predicting Columns in a Table - In Depth__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing AutoGluon, specifying TabularPrediction as the task, and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon as ag\n",
    "from autogluon import TabularPrediction as task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    }
   ],
   "source": [
    "train_data = task.Dataset(file_path='https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "#train_data = train_data.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39073, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>178478</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt   education  education-num  marital-status  \\\n",
       "0   25   Private  178478   Bachelors             13   Never-married   \n",
       "\n",
       "      occupation relationship    race      sex  capital-gain  capital-loss  \\\n",
       "0   Tech-support    Own-child   White   Female             0             0   \n",
       "\n",
       "   hours-per-week  native-country   class  \n",
       "0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not wish to provide a validation dataset, __it is recommended that you omit the tuning_data argument. This lets AutoGluon automatically select validation data from your provided training set__ (it uses smart strategies such as stratified sampling). For greater control, you can specify the holdout_frac argument to tell AutoGluon what fraction of the provided training data to hold out for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of occupation column: \n",
      " count               39073\n",
      "unique                 15\n",
      "top        Prof-specialty\n",
      "freq                 4949\n",
      "Name: occupation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "label_column = 'occupation'\n",
    "val_data = task.Dataset(file_path='https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "print(\"Summary of occupation column: \\n\", train_data['occupation'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Exec-managerial', ' Craft-repair', ' Handlers-cleaners',\n",
       "       ' Adm-clerical', ' Other-service', ' Sales', ' ?',\n",
       "       ' Protective-serv', ' Farming-fishing', ' Transport-moving',\n",
       "       ' Prof-specialty', ' Machine-op-inspct', ' Tech-support'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.unique(train_data[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether or not to do hyperparameter optimization\n",
    "hp_tune = True\n",
    "\n",
    "# specifies non-default hyperparameter values for neural network models\n",
    "nn_options = {\n",
    "    'num_epochs': 100, # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True), # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'), # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'layers': ag.space.Categorical([100],[1000],[200,100],[300,200,100]),\n",
    "      # Each choice for categorical hyperparameter 'layers' corresponds to list of sizes for each NN layer to use\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1), # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = { # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100, # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36), # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "hyperparameters = {'NN': nn_options, 'GBM': gbm_options}  # hyperparameters of each model type\n",
    "# If one of these keys is missing from hyperparameters dict, then no models of that type are trained.\n",
    "\n",
    "time_limits = 2*60  # train various models for ~2 min\n",
    "num_trials = 5  # try at most 3 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'skopt'  # to tune hyperparameters using SKopt Bayesian optimization routine\n",
    "output_directory = 'output'  # folder where to store trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two other methods to boost predictive performance are bagging and stack-ensembling. You’ll often see performance improve if you specify num_bagging_folds = 5-10, stack_ensemble_levels = 1 or 2 in the call to fit(), but this will increase training times.\n",
    "\n",
    "- num_bagging_folds : (int)\\\n",
    "Number of folds used for bagging of models. When `num_bagging_folds = k`, training time is roughly increased by a factor of `k` (set = 0 to disable bagging).\\\n",
    "Disabled by default, but we recommend values between 5-10 to maximize predictive performance. \n",
    "    \n",
    "- stack_ensemble_levels : (int)\\\n",
    "Number of stacking levels to use in stack ensemble. Roughly increases model training time by factor of `stack_ensemble_levels+1` (set = 0 to disable stack ensembling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Specified num_trials == 1 or time_limits is too small for hyperparameter_tune, setting to False.\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [' Tech-support' ' Transport-moving' ' Other-service' ' ?'\n",
      " ' Handlers-cleaners' ' Sales' ' Craft-repair' ' Adm-clerical'\n",
      " ' Exec-managerial' ' Prof-specialty']\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == object)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "\tData preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "Fitting model: LightGBMClassifier ... Training model for up to 59.9s of the 119.81s of remaining time.\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 20. Best iteration is:\n",
      "\t[17]\ttrain_set's multi_error: 0.577418\ttrain_set's multi_logloss: 1.78784\ttrain_set's accuracy: 0.422582\tvalid_set's multi_error: 0.602762\tvalid_set's multi_logloss: 1.86619\tvalid_set's accuracy: 0.397238\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 22. Best iteration is:\n",
      "\t[20]\ttrain_set's multi_error: 0.573867\ttrain_set's multi_logloss: 1.74661\ttrain_set's accuracy: 0.426133\tvalid_set's multi_error: 0.605301\tvalid_set's multi_logloss: 1.84542\tvalid_set's accuracy: 0.394699\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 23. Best iteration is:\n",
      "\t[20]\ttrain_set's multi_error: 0.569546\ttrain_set's multi_logloss: 1.74385\ttrain_set's accuracy: 0.430454\tvalid_set's multi_error: 0.61288\tvalid_set's multi_logloss: 1.84342\tvalid_set's accuracy: 0.38712\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 24. Best iteration is:\n",
      "\t[23]\ttrain_set's multi_error: 0.569952\ttrain_set's multi_logloss: 1.71279\ttrain_set's accuracy: 0.430048\tvalid_set's multi_error: 0.611162\tvalid_set's multi_logloss: 1.82468\tvalid_set's accuracy: 0.388838\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\t[27]\ttrain_set's multi_error: 0.56959\ttrain_set's multi_logloss: 1.68959\ttrain_set's accuracy: 0.43041\tvalid_set's multi_error: 0.595309\tvalid_set's multi_logloss: 1.78297\tvalid_set's accuracy: 0.404691\n",
      "\t56.8s\t = Training runtime\n",
      "\t0.3945\t = Validation accuracy score\n",
      "Fitting model: NeuralNetClassifier ... Training model for up to 3.09s of the 63.0s of remaining time.\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, stopping training early.\n",
      "\tTime limit exceeded... Skipping NeuralNetClassifier.\n",
      "Fitting model: weighted_ensemble_l1 ...\n",
      "\t0.02s\t = Training runtime\n",
      "\t0.3945\t = Validation accuracy score\n",
      "Fitting model: LightGBMClassifier_STACKER_l1 ... Training model for up to 58.59s of the 58.59s of remaining time.\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 21. Best iteration is:\n",
      "\t[20]\ttrain_set's multi_error: 0.549978\ttrain_set's multi_logloss: 1.73278\ttrain_set's accuracy: 0.450022\tvalid_set's multi_error: 0.613504\tvalid_set's multi_logloss: 1.89614\tvalid_set's accuracy: 0.386496\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 21. Best iteration is:\n",
      "\t[14]\ttrain_set's multi_error: 0.557819\ttrain_set's multi_logloss: 1.78648\ttrain_set's accuracy: 0.442181\tvalid_set's multi_error: 0.613283\tvalid_set's multi_logloss: 1.90867\tvalid_set's accuracy: 0.386717\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 23. Best iteration is:\n",
      "\t[21]\ttrain_set's multi_error: 0.54508\ttrain_set's multi_logloss: 1.68477\ttrain_set's accuracy: 0.45492\tvalid_set's multi_error: 0.617692\tvalid_set's multi_logloss: 1.8524\tvalid_set's accuracy: 0.382308\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 25. Best iteration is:\n",
      "\t[18]\ttrain_set's multi_error: 0.548763\ttrain_set's multi_logloss: 1.73763\ttrain_set's accuracy: 0.451237\tvalid_set's multi_error: 0.606452\tvalid_set's multi_logloss: 1.86745\tvalid_set's accuracy: 0.393548\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\t[27]\ttrain_set's multi_error: 0.535403\ttrain_set's multi_logloss: 1.62538\ttrain_set's accuracy: 0.464597\tvalid_set's multi_error: 0.607395\tvalid_set's multi_logloss: 1.80738\tvalid_set's accuracy: 0.392605\n",
      "\t55.48s\t = Training runtime\n",
      "\t0.3883\t = Validation accuracy score\n",
      "Fitting model: NeuralNetClassifier_STACKER_l1 ... Training model for up to 3.1s of the 3.1s of remaining time.\n",
      "Attempting to fit model without HPO, but search space is provided. fit() will only consider default hyperparameter values from search space.\n",
      "\tRan out of time, stopping training early.\n",
      "\tTime limit exceeded... Skipping NeuralNetClassifier_STACKER_l1.\n",
      "Fitting model: weighted_ensemble_l2 ...\n",
      "\t0.02s\t = Training runtime\n",
      "\t0.3883\t = Validation accuracy score\n",
      "AutoGluon training complete, total runtime = 124.25s ...\n"
     ]
    }
   ],
   "source": [
    "predictor = task.fit(train_data=train_data, tuning_data=val_data, label=label_column,\n",
    "                     output_directory=output_directory, time_limits=time_limits, num_trials=num_trials,\n",
    "                     hyperparameter_tune=hp_tune, hyperparameters=hyperparameters,\n",
    "                     search_strategy=search_strategy, num_bagging_folds=5, stack_ensemble_levels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again demonstrate how to use the trained models to predict on the validation data. <span class=\"burk\">We caution again that performance estimates from this data may be biased because the same  data was used to tune hyperparameters.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = val_data.copy()\n",
    "y_test = test_data[label_column]\n",
    "test_data.drop(labels=[label_column],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_data.columns == label_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>19</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>27382</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   workclass  fnlwgt      education  education-num  marital-status  \\\n",
       "2111   19   Local-gov   27382   Some-college             10   Never-married   \n",
       "\n",
       "     relationship    race    sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "2111    Own-child   White   Male             0             0              40   \n",
       "\n",
       "      native-country   class  \n",
       "2111   United-States   <=50K  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.424813\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.4248131845634149,\n",
      "    \"accuracy_score\": 0.4248131845634149,\n",
      "    \"balanced_accuracy_score\": 0.40748268871019905,\n",
      "    \"matthews_corrcoef\": 0.3603755551444519\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [' Other-service', ' Farming-fishing', ' Exec-managerial', ' Other-service', ' Other-service']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detailed (per-class) classification report:\n",
      "{\n",
      "    \" ?\": {\n",
      "        \"precision\": 1.0,\n",
      "        \"recall\": 0.99830220713073,\n",
      "        \"f1-score\": 0.9991503823279524,\n",
      "        \"support\": 589\n",
      "    },\n",
      "    \" Adm-clerical\": {\n",
      "        \"precision\": 0.39043309631544926,\n",
      "        \"recall\": 0.5206896551724138,\n",
      "        \"f1-score\": 0.44625046176579247,\n",
      "        \"support\": 1160\n",
      "    },\n",
      "    \" Armed-Forces\": {\n",
      "        \"precision\": 0.2,\n",
      "        \"recall\": 1.0,\n",
      "        \"f1-score\": 0.33333333333333337,\n",
      "        \"support\": 2\n",
      "    },\n",
      "    \" Craft-repair\": {\n",
      "        \"precision\": 0.3275186899252403,\n",
      "        \"recall\": 0.7204385277995301,\n",
      "        \"f1-score\": 0.45031815956926086,\n",
      "        \"support\": 1277\n",
      "    },\n",
      "    \" Exec-managerial\": {\n",
      "        \"precision\": 0.39718804920913886,\n",
      "        \"recall\": 0.36044657097288674,\n",
      "        \"f1-score\": 0.37792642140468224,\n",
      "        \"support\": 1254\n",
      "    },\n",
      "    \" Farming-fishing\": {\n",
      "        \"precision\": 0.45121951219512196,\n",
      "        \"recall\": 0.2868217054263566,\n",
      "        \"f1-score\": 0.35071090047393366,\n",
      "        \"support\": 258\n",
      "    },\n",
      "    \" Handlers-cleaners\": {\n",
      "        \"precision\": 0.35294117647058826,\n",
      "        \"recall\": 0.058394160583941604,\n",
      "        \"f1-score\": 0.10020876826722339,\n",
      "        \"support\": 411\n",
      "    },\n",
      "    \" Machine-op-inspct\": {\n",
      "        \"precision\": 0.4752475247524752,\n",
      "        \"recall\": 0.07907742998352553,\n",
      "        \"f1-score\": 0.13559322033898305,\n",
      "        \"support\": 607\n",
      "    },\n",
      "    \" Other-service\": {\n",
      "        \"precision\": 0.3684210526315789,\n",
      "        \"recall\": 0.447939262472885,\n",
      "        \"f1-score\": 0.4043073910915321,\n",
      "        \"support\": 922\n",
      "    },\n",
      "    \" Priv-house-serv\": {\n",
      "        \"precision\": 0.6666666666666666,\n",
      "        \"recall\": 0.4186046511627907,\n",
      "        \"f1-score\": 0.5142857142857143,\n",
      "        \"support\": 43\n",
      "    },\n",
      "    \" Prof-specialty\": {\n",
      "        \"precision\": 0.5058986814712005,\n",
      "        \"recall\": 0.5960752248569092,\n",
      "        \"f1-score\": 0.5472972972972973,\n",
      "        \"support\": 1223\n",
      "    },\n",
      "    \" Protective-serv\": {\n",
      "        \"precision\": 0.425414364640884,\n",
      "        \"recall\": 0.36666666666666664,\n",
      "        \"f1-score\": 0.39386189258312027,\n",
      "        \"support\": 210\n",
      "    },\n",
      "    \" Sales\": {\n",
      "        \"precision\": 0.33181818181818185,\n",
      "        \"recall\": 0.13773584905660377,\n",
      "        \"f1-score\": 0.19466666666666668,\n",
      "        \"support\": 1060\n",
      "    },\n",
      "    \" Tech-support\": {\n",
      "        \"precision\": 1.0,\n",
      "        \"recall\": 0.003401360544217687,\n",
      "        \"f1-score\": 0.006779661016949153,\n",
      "        \"support\": 294\n",
      "    },\n",
      "    \" Transport-moving\": {\n",
      "        \"precision\": 0.40601503759398494,\n",
      "        \"recall\": 0.11764705882352941,\n",
      "        \"f1-score\": 0.18243243243243243,\n",
      "        \"support\": 459\n",
      "    },\n",
      "    \"accuracy\": 0.4248131845634149,\n",
      "    \"macro avg\": {\n",
      "        \"precision\": 0.48658546891270066,\n",
      "        \"recall\": 0.40748268871019905,\n",
      "        \"f1-score\": 0.3624748468569916,\n",
      "        \"support\": 9769\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"precision\": 0.45215031567806097,\n",
      "        \"recall\": 0.4248131845634149,\n",
      "        \"f1-score\": 0.38988481588425616,\n",
      "        \"support\": 9769\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "\n",
    "print(\"Predictions:  \", list(y_pred)[:5])\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictor can also make a prediction on an individual example rather than a full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>75</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>192813</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          workclass  fnlwgt education  education-num marital-status  \\\n",
       "8911   75   Self-emp-not-inc  192813   Masters             14        Widowed   \n",
       "\n",
       "        relationship    race    sex  capital-gain  capital-loss  \\\n",
       "8911   Not-in-family   White   Male             0             0   \n",
       "\n",
       "      hours-per-week  native-country   class  \n",
       "8911              45   United-States   <=50K  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint = test_data.sample(1)  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
    "datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [' Prof-specialty']\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction:\", predictor.predict(datapoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following to view a summary of what happened during fit. This command will shows details of the hyperparameter-tuning process for each type of model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Number of models trained: 4\n",
      "Types of models trained: \n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel', 'BaggedEnsembleModel'}\n",
      "Validation performance of individual models: {'LightGBMClassifier_BAGGED_l0': 0.3945170140452889, 'weighted_ensemble_l1': 0.3945170140452889, 'LightGBMClassifier_STACKER_l1': 0.38833381106424797, 'weighted_ensemble_l2': 0.38833381106424797}\n",
      "Best model (based on validation performance): weighted_ensemble_l1\n",
      "Hyperparameter-tuning used: False\n",
      "Bagging used: True  (with 5 folds)\n",
      "Stack-ensembling used: True  (with 1 levels)\n",
      "User-specified hyperparameters:\n",
      "{'NN': {'num_epochs': 100, 'learning_rate': Real: lower=0.0001, upper=0.01, 'activation': Categorical['relu', 'softrelu', 'tanh'], 'layers': Categorical[[100], [1000], [200, 100], [300, 200, 100]], 'dropout_prob': Real: lower=0.0, upper=0.5}, 'GBM': {'num_boost_round': 100, 'num_leaves': Int: lower=26, upper=66}}\n",
      "Plot summary of models saved to file: SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labs/anaconda3/envs/deploy/lib/python3.6/site-packages/autogluon/utils/plots.py:133: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. Please do: \"pip install bokeh\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. Please do: \"pip install bokeh\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
